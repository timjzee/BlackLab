(window.webpackJsonp=window.webpackJsonp||[]).push([[26],{301:function(e,a,t){"use strict";t.r(a);var s=t(13),o=Object(s.a)({},(function(){var e=this,a=e._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"corpus-query-language"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#corpus-query-language"}},[e._v("#")]),e._v(" Corpus Query Language")]),e._v(" "),a("p",[e._v("BlackLab supports Corpus Query Language, a full-featured query language introduced by the IMS Corpus WorkBench (CWB) and also supported by the Lexicom Sketch Engine, among several other corpus engines. It is a de-facto standard and powerful way of searching corpora.")]),e._v(" "),a("p",[e._v("The basics of Corpus Query Language is the same in all three projects, but in there are a few minor differences in some of the more advanced features, as well as some features that are exclusive to some projects. For most queries however, this will not be an issue.")]),e._v(" "),a("p",[e._v("This page will introduce the query language and show all features that BlackLab supports. If you want to learn even more about CQL, see "),a("a",{attrs:{href:"http://cwb.sourceforge.net/files/CQP_Tutorial/",title:"http://cwb.sourceforge.net/files/CQP_Tutorial/",target:"_blank",rel:"noopener noreferrer"}},[e._v("CWB CQP Query Language Tutorial"),a("OutboundLink")],1),e._v(" and "),a("a",{attrs:{href:"https://www.sketchengine.co.uk/documentation/corpus-querying/",title:"https://www.sketchengine.co.uk/documentation/corpus-querying/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Sketch Engine Corpus Query Language"),a("OutboundLink")],1),e._v(".")]),e._v(" "),a("h2",{attrs:{id:"cql-support"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#cql-support"}},[e._v("#")]),e._v(" CQL support")]),e._v(" "),a("p",[e._v("For those who already know CQL, here's a quick overview of the extent of BlackLab's support for this query language. If you a feature we don't support yet is important to you, please let us know. If it's quick to add, we may be able to help you out.")]),e._v(" "),a("h3",{attrs:{id:"supported-features"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#supported-features"}},[e._v("#")]),e._v(" Supported features")]),e._v(" "),a("p",[e._v("BlackLab currently supports (arguably) most of the important features of Corpus Query Language:")]),e._v(" "),a("ul",[a("li",[e._v("Matching on token annotations (also called properties or attributes), using regular expressions and "),a("code",[e._v("=")]),e._v(", "),a("code",[e._v("!=")]),e._v(", "),a("code",[e._v("!")]),e._v(". Example: "),a("code",[e._v('[word="bank"]')]),e._v(" (or just "),a("code",[e._v('"bank"')]),e._v(")")]),e._v(" "),a("li",[e._v("Case/accent sensitive matching. Note that, unlike in CWB, case-INsensitive matching is currently the default. To explicitly match case-/accent-insensitively, use "),a("code",[e._v('"(?i)..."')]),e._v(". Example: "),a("code",[e._v('"(?-i)Mr\\." "(?-i)Banks"')])]),e._v(" "),a("li",[e._v("Combining criteria using "),a("code",[e._v("&")]),e._v(", "),a("code",[e._v("|")]),e._v(" and "),a("code",[e._v("!")]),e._v(". Parentheses can also be used for grouping. Example: "),a("code",[e._v('[lemma="bank" & pos="V"]')])]),e._v(" "),a("li",[e._v("Matchall pattern "),a("code",[e._v("[]")]),e._v(" matches any token. Example: "),a("code",[e._v('"a" [] "day"')])]),e._v(" "),a("li",[e._v("Regular expression operators "),a("code",[e._v("+")]),e._v(", "),a("code",[e._v("*")]),e._v(", "),a("code",[e._v("?")]),e._v(", "),a("code",[e._v("{n}")]),e._v(", "),a("code",[e._v("{n,m}")]),e._v(" at the token level. Example: "),a("code",[e._v('[pos="ADJ"]+')])]),e._v(" "),a("li",[e._v("Sequences of token constraints. Example: "),a("code",[e._v('[pos="ADJ"] "cow"')])]),e._v(" "),a("li",[e._v("Operators "),a("code",[e._v("|")]),e._v(", "),a("code",[e._v("&")]),e._v(" and parentheses can be used to build complex sequence queries. Example: "),a("code",[e._v('"happy" "dog" | "sad" cat"')])]),e._v(" "),a("li",[e._v("Querying with tag positions using e.g. "),a("code",[e._v("<s>")]),e._v(" (start of sentence), "),a("code",[e._v("</s>")]),e._v(" (end of sentence), "),a("code",[e._v("<s/>")]),e._v(" (whole sentence) or "),a("code",[e._v("<s> ... </s>")]),e._v(" (equivalent to "),a("code",[e._v("<s/> containing ...")]),e._v("). Example: "),a("code",[e._v('<s> "The"')]),e._v(". XML attribute values may be used as well, e.g. "),a("code",[e._v('<ne type="PERS"/>')]),e._v(' ("named entities that are persons").')]),e._v(" "),a("li",[e._v("Using "),a("code",[e._v("within")]),e._v(" and "),a("code",[e._v("containing")]),e._v(" operators to find hits inside another set of hits. Example: "),a("code",[e._v('"you" "are" within <s/>')])]),e._v(" "),a("li",[e._v("Using an anchor to capture a token position. Example: "),a("code",[e._v('"big" A:[]')]),e._v(". Captured matches can be used in global constraints (see next item) or processed separately later (using the Java interface; capture information is not yet returned by BlackLab Server). Note that BlackLab can actually capture entire groups of tokens as well, similarly to regular expression engines.")]),e._v(" "),a("li",[e._v("Global constraints on captured tokens, such as requiring them to contain the same word. Example: "),a("code",[e._v('"big" A:[] "or" "small" B:[] :: A.word = B.word')])])]),e._v(" "),a("p",[e._v("See below for features not in this list that may be added soon, and let us know if you want a particular feature to be added.")]),e._v(" "),a("h3",{attrs:{id:"differences-from-cwb"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#differences-from-cwb"}},[e._v("#")]),e._v(" Differences from CWB")]),e._v(" "),a("p",[e._v("BlackLab's CQL syntax and behaviour differs in a few small ways from CWBs. In future, we'll aim towards greater compliance with CWB's de-facto standard (with some extra features and conveniences).")]),e._v(" "),a("p",[e._v("For now, here's what you should know:")]),e._v(" "),a("ul",[a("li",[e._v("Case-insensitive search is currently the default in BlackLab, although you can change this if you wish. CWB and Sketch Engine use case-sensitive search as the default. We may change our default in a future major version."),a("br"),e._v("\nIf you want to switch case/diacritics sensitivity, use "),a("code",[e._v('"(?-i).."')]),e._v(" (case sensitive) or "),a("code",[e._v('"(?i).."')]),e._v(" (case insensitive, usually the default). CWBs "),a("code",[e._v("%cd")]),e._v(" flags for setting case/diacritics-sensitivity are not (yet) supported, but will be added.")]),e._v(" "),a("li",[e._v("If you want to match a string literally, not as a regular expression, use backslash escaping: "),a("code",[e._v('"e\\.g\\."')]),e._v(". "),a("code",[e._v("%l")]),e._v(" for literal matching is not yet supported, but will be added.")]),e._v(" "),a("li",[e._v("BlackLab supports result set manipulation such as: sorting (including on specific context words), grouping/frequency distribution, subsets, sampling, setting context size, etc. However, these are supported through the REST and Java APIs, not through a command interface like in CWB. See "),a("RouterLink",{attrs:{to:"/server/overview.html"}},[e._v("BlackLab Server overview")]),e._v(").")],1),e._v(" "),a("li",[e._v("Querying XML elements and attributes looks natural in BlackLab: "),a("code",[e._v("<s/>")]),e._v(' means "sentences", '),a("code",[e._v("<s>")]),e._v(' means "starts of sentences", '),a("code",[e._v("<s type='A'>")]),e._v(' means "sentence tags with a type attribute with value A". This natural syntax differs from CWBs in some places, however, particularly when matching XML attributes. While we believe our syntax is the superior one, we may add support for the CWB syntax as an alternative.'),a("br"),e._v("\nWe only support literal matching of XML attributes at the moment, but this will be expanded to full regex matching.")]),e._v(" "),a("li",[e._v("In global constraints (expressions occurring after "),a("code",[e._v("::")]),e._v("), only literal matching (no regex matching) is currently supported. Regex matching will be added soon. For now, instead of "),a("code",[e._v('A:[] "dog" :: A.word = "happy|sad"')]),e._v(", use "),a("code",[e._v('"happy|sad" "dog"')]),e._v(".")]),e._v(" "),a("li",[e._v("To expand your query to return whole sentences, use "),a("code",[e._v("<s/> containing (...)")]),e._v(". We don't yet support CWBs "),a("code",[e._v("expand to")]),e._v(", "),a("code",[e._v("expand left to")]),e._v(", etc., but may add this in the future.")]),e._v(" "),a("li",[e._v("The implication operator "),a("code",[e._v("->")]),e._v(" is currently only supported in global constraints (expressions after the "),a("code",[e._v("::")]),e._v(" operator), not in a regular token constraints. We may add this if there's demand for it.")]),e._v(" "),a("li",[e._v("We don't support the "),a("code",[e._v("@")]),e._v(" anchor and corresponding "),a("code",[e._v("target")]),e._v(" label; use a named anchor instead. If someone makes a good case for it, we will consider adding this feature.")]),e._v(" "),a("li",[e._v("backreferences to anchors only work in global constraints, so this doesn't work: "),a("code",[e._v("A:[] [] [word = A.word]")]),e._v(". Instead, use something like: "),a("code",[e._v("A:[] [] B:[] :: A.word = B.word")]),e._v(". We hope to add support for these in the near future, but our matching approach may not allow full support for this in all cases.")])]),e._v(" "),a("h3",{attrs:{id:"currently-unsupported-features"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#currently-unsupported-features"}},[e._v("#")]),e._v(" (Currently) unsupported features")]),e._v(" "),a("p",[e._v("The following features are not (yet) supported:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("intersection")]),e._v(", "),a("code",[e._v("union")]),e._v(" and "),a("code",[e._v("difference")]),e._v(" operators. These three operators will be added in the future. For now, the first two can be achieved using "),a("code",[e._v("&")]),e._v(" and "),a("code",[e._v("|")]),e._v(" at the sequence level, e.g. "),a("code",[e._v('"double" [] & [] "trouble"')]),e._v(' to match the intersection of these queries, i.e. "double trouble" and '),a("code",[e._v('"happy" "dog" | "sad "cat"')]),e._v(' to match the union of "happy dog" and "sad cat".')]),e._v(" "),a("li",[a("code",[e._v("_")]),e._v(' meaning "the current token" in token constraints. We will add this soon.')]),e._v(" "),a("li",[a("code",[e._v("lbound")]),e._v(", "),a("code",[e._v("rbound")]),e._v(" functions to get the edge of a region. We will probably add these.")]),e._v(" "),a("li",[a("code",[e._v("distance")]),e._v(", "),a("code",[e._v("distabs")]),e._v(" functions and "),a("code",[e._v("match")]),e._v(", "),a("code",[e._v("matchend")]),e._v(" anchor points (sometimes used in global constraints). We will see about adding these.")]),e._v(" "),a("li",[e._v("using an XML element name to mean 'token is contained within', like "),a("code",[e._v('[(pos = "N") & !np]')]),e._v(' meaning "noun NOT inside in an '),a("code",[e._v("<np/>")]),e._v(' tag". We will see about adding these.')]),e._v(" "),a("li",[e._v("a number of less well-known features. If people ask, we will consider adding them.")])]),e._v(" "),a("h2",{attrs:{id:"using-corpus-query-language"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#using-corpus-query-language"}},[e._v("#")]),e._v(" Using Corpus Query Language")]),e._v(" "),a("h3",{attrs:{id:"matching-tokens"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#matching-tokens"}},[e._v("#")]),e._v(" Matching tokens")]),e._v(" "),a("p",[e._v('Corpus Query Language is a way to specify a "pattern" of tokens (i.e. words) you\'re looking for. A simple pattern is this one:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('[word="man"]\n')])])]),a("p",[e._v('This simply searches for all occurrences of the word "man". If your corpus includes the per-word properties lemma (i.e. headword) and pos (part-of-speech, i.e. noun, verb, etc.), you can query those as well. For example, to find a form of word "search" used as a noun, use this query:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('[lemma="search" & pos="NOU"]\n')])])]),a("p",[e._v('This query would match "search" and "searches" where used as a noun. (Of course, your data may contain slightly different part-of-speech tags.)')]),e._v(" "),a("p",[e._v('The first query could be written even simpler without brackets, assuming "word" is the default annotation:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('"man"\n')])])]),a("p",[e._v('You can use the "does not equal" operator (!=) to search for all words except nouns:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('[pos != "NOU"]\n')])])]),a("p",[e._v("The strings between quotes can also contain wildcards, of sorts. To be precise, they are "),a("a",{attrs:{href:"http://en.wikipedia.org/wiki/Regular_expression",target:"_blank",rel:"noopener noreferrer"}},[e._v("regular expressions"),a("OutboundLink")],1),e._v(', which provide a flexible way of matching strings of text. For example, to find "man" or "woman", use:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('"(wo)?man"\n')])])]),a("p",[e._v('And to find lemmata starting with "under", use:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('[lemma="under.\\*"]\n')])])]),a("p",[e._v("Explaining regular expression syntax is beyond the scope of this document, but for a complete overview, see "),a("a",{attrs:{href:"http://www.regular-expressions.info/",target:"_blank",rel:"noopener noreferrer"}},[e._v("regular-expressions.info"),a("OutboundLink")],1),e._v(".")]),e._v(" "),a("h3",{attrs:{id:"sequences"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sequences"}},[e._v("#")]),e._v(" Sequences")]),e._v(" "),a("p",[e._v('Corpus Query Language allows you to search for sequences of words as well (i.e. phrase searches, but with many more possibilities). To search for the phrase "the tall man", use this query:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('"the" "tall" "man"\n')])])]),a("p",[e._v('It might seem a bit clunky to separately quote each word, but this allow us the flexibility to specify exactly what kinds of words we\'re looking for. For example, if you want to know all single adjectives used with man (not just "tall"), use this:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('"an?|the" [pos="ADJ"] "man"\n')])])]),a("p",[e._v('This would also match "a wise man", "an important man", "the foolish man", etc.')]),e._v(" "),a("h3",{attrs:{id:"regular-expression-operators-on-tokens"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#regular-expression-operators-on-tokens"}},[e._v("#")]),e._v(" Regular expression operators on tokens")]),e._v(" "),a("p",[e._v('Corpus Query Language really starts to shine when you use the regular expression operators on whole tokens as well. If we want to see not just single adjectives applied to "man", but multiple as well:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('"an?|the" [pos="ADJ"]+ "man"\n')])])]),a("p",[e._v('This query matches "a little green man", for example. The plus sign after [pos="ADJ"] says that the preceding part should occur one or more times (similarly, * means "zero or more times", and ? means "zero or one time").')]),e._v(" "),a("p",[e._v("If you only want matches with two or three adjectives, you can specify that too:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('"an?|the" [pos="ADJ"]{2,3} "man"\n')])])]),a("p",[e._v("Or, for two or more adjectives:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('"an?|the" [pos="ADJ"]{2,} "man"\n')])])]),a("p",[e._v("You can group sequences of tokens with parentheses and apply operators to the whole group as well. To search for a sequence of nouns, each optionally preceded by an article:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('("an?|the"? [pos="NOU"])+\n')])])]),a("p",[e._v('This would, for example, match the well-known palindrome "a man, a plan, a canal: Panama!" (A note about punctuation: in BlackLab, punctuation tends to not be indexed as a separate token, but as an annotation of a word token - CWB and Sketch Engine on the other hand tend to index punctuation as a separate token instead. You certainly could choose to index punctuation as a separate token in BlackLab, by the way -- it\'s just not commonly done. Both approaches have their advantages and disadvantages, and of course the choice affects how you write your queries.)')]),e._v(" "),a("h3",{attrs:{id:"case-and-diacritics-sensitivity"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#case-and-diacritics-sensitivity"}},[e._v("#")]),e._v(" Case- and diacritics sensitivity")]),e._v(" "),a("p",[e._v('CWB and Sketch Engine both default to (case- and diacritics) sensitive search. That is, they exactly match upper- and lowercase letters in your query, plus any accented letters in the query as well. BlackLab, on the contrary, defaults to *IN*sensitive search (although this default can be changed if you like). To match a pattern sensitively, prefix it with "(?-i)":')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('"(?-i)Panama"\n')])])]),a("p",[e._v('If you\'ve changed the default search to sensitive, but you wish to match a pattern in your query insensitively, prefix it with "(?i)":')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('[pos="(?i)nou"]\n')])])]),a("p",[e._v("Although BlackLab is capable of setting case- and diacritics-sensitivity separately, it is not yet possible from Corpus Query Language. We may add this capability if requested.")]),e._v(" "),a("h3",{attrs:{id:"matching-xml-elements"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#matching-xml-elements"}},[e._v("#")]),e._v(" Matching XML elements")]),e._v(" "),a("p",[e._v('Corpus Query Language allows you to find text in relation to XML elements that occur in it. For example, if your data contains sentence tags, you could look for sentences starting with "the":')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('<s>"the"\n')])])]),a("p",[e._v('Similarly, to find sentences ending in "that", you would use:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('"that"</s>\n')])])]),a("p",[e._v("You can also search for words occurring inside a specific element. Say you've run named entity recognition on your data and all person names are surrounded with <person>...</person> tags. To find the word \"baker\" as part of a person's name, use:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('"baker" within <person/>\n')])])]),a("p",[e._v('Note that forward slash at the end of the tag. This way of referring to the element means "the whole element". Compare to <person>, which means "the element\'s open tag", and </person>, which means "the element\'s close tag".')]),e._v(" "),a("p",[e._v('The above query will just match the word "baker" as part of a person\'s name. But you\'re likely more interested in the entire name that contains the word "baker". So, to find those full names, use:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('<person/> containing "baker"\n')])])]),a("p",[e._v("Or, if you simply want to find all persons, use:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v("<person/>\n")])])]),a("p",[e._v('As you can see, the XML element reference is just another query that yields a number of matches. So as you might have guessed, you can use "within" and "containing" with any other query as well. For example:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('([pos="ADJ"]+ containing "tall") "man"\n')])])]),a("p",[e._v('will find adjectives applied to man, where one of those adjectives is "tall".')]),e._v(" "),a("h3",{attrs:{id:"labeling-tokens-capturing-groups"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#labeling-tokens-capturing-groups"}},[e._v("#")]),e._v(" Labeling tokens, capturing groups")]),e._v(" "),a("p",[e._v('Just like in regular expressions, it is possible to "capture" part of the match for your query in a "group".')]),e._v(" "),a("p",[e._v("CWB and Sketch Engine offer similar functionality, but instead of capturing part of the query, they label a single token. BlackLab's functionality is very similar but can capture a number of tokens as well.")]),e._v(" "),a("p",[e._v("Example:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('"an?|the" Adjectives:[pos="ADJ"]+ "man"\n')])])]),a("p",[e._v('This will capture the adjectives found for each match in a captured group named "Adjectives". BlackLab also supports numbered groups:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('"an?|the" 1:[pos="ADJ"]+ "man"\n')])])]),a("h3",{attrs:{id:"global-constraints"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#global-constraints"}},[e._v("#")]),e._v(" Global constraints")]),e._v(" "),a("p",[e._v('If you tag certain tokens with labels, you can also apply "global constraints" on these tokens. This is a way of relating different tokens to one another, for example requiring that they correspond to the same word:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[e._v('A:[] "by" B:[] :: A.word = B.word\n')])])]),a("p",[e._v('This would match "day by day", "step by step", etc.')])])}),[],!1,null,null,null);a.default=o.exports}}]);